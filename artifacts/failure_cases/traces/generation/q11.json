{
  "timestamp": "2026-01-31T17:39:24.570882",
  "phase": "generation",
  "query": "Why is masking applied in the decoder self-attention layer?",
  "metadata": {
    "question_id": 11,
    "generation_case": "G-B5",
    "expected_behavior": "HEDGE"
  },
  "evidence_summary": {
    "evidence_present": true,
    "sufficiency": "conflicting",
    "max_similarity": 19.69035338836192,
    "coverage_score": 0.0,
    "conflicting_sources": true,
    "rationale": "Multiple high-scoring sources retrieved; treat as potentially conflicting."
  },
  "policy_decision": {
    "allowed": "hedge",
    "refusal_code": null
  },
  "output": {
    "type": "hedge",
    "hedge_code": "conflicting_sources"
  }
}